{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2148ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-binance\n",
    "# !pip install python-dotenv\n",
    "# !pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a2f411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78c3de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Para dividir os dados\n",
    "from sklearn.ensemble import RandomForestClassifier # O algoritmo de Floresta Aleatória\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # Métricas de avaliação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18098d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "API_SECRET = os.getenv(\"API_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c52bd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com a Binance estabelecida com sucesso!\n",
      "\n",
      "Buscando os últimos 2500 candlesticks de BTCUSDT no intervalo de 1h...\n"
     ]
    }
   ],
   "source": [
    "if not API_KEY or not API_SECRET:\n",
    "    print(\"Erro: As chaves API_KEY ou API_SECRET não foram carregadas do arquivo .env.\")\n",
    "    print(\"Verifique se o arquivo .env existe na mesma pasta e se as variáveis estão corretas.\")\n",
    "    exit() # Sai do programa se as chaves não forem encontradas\n",
    "\n",
    "# 4. Inicializa o cliente da Binance (mesmo código de antes)\n",
    "try:\n",
    "    client = Client(API_KEY, API_SECRET)\n",
    "    print(\"Conexão com a Binance estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar com a Binance: {e}\")\n",
    "    print(\"Verifique suas chaves de API e sua conexão com a internet.\")\n",
    "    exit()\n",
    "\n",
    "# 5. Define os parâmetros para a busca dos dados de candlestick (mesmo código de antes)\n",
    "symbol = 'BTCUSDT'\n",
    "interval = '1h'\n",
    "limit = 2500\n",
    "\n",
    "print(f\"\\nBuscando os últimos {limit} candlesticks de {symbol} no intervalo de {interval}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0150306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Faz a requisição para a API da Binance\n",
    "klines = client.get_historical_klines(symbol, interval, limit=limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "051ccb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Processa os dados brutos e os organiza em um DataFrame do Pandas\n",
    "data = []\n",
    "for kline in klines:\n",
    "    data.append({\n",
    "        'timestamp': kline[0],\n",
    "        'open': float(kline[1]),\n",
    "        'high': float(kline[2]),\n",
    "        'low': float(kline[3]),\n",
    "        'close': float(kline[4]),\n",
    "        'volume': float(kline[5])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Armazenar o DataFrame original antes de renomear colunas\n",
    "# para que possamos usar 'close' para o cálculo do label\n",
    "df_original_cols = df.copy()\n",
    "\n",
    "# Assegura que as colunas numéricas estão no tipo correto para pandas_ta\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2931e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adicionando indicadores técnicos ao DataFrame...\n",
      "Indicadores adicionados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Adicionar Indicadores Técnicos (Feature Engineering) ---\n",
    "print(\"\\nAdicionando indicadores técnicos ao DataFrame...\")\n",
    "\n",
    "# Média Móvel Simples (SMA) de 20 períodos\n",
    "# df.ta.sma(length=20, append=True) adiciona a coluna 'SMA_20' diretamente ao DataFrame\n",
    "df.ta.sma(length=20, append=True)\n",
    "\n",
    "# Bandas de Bollinger (BBands)\n",
    "# bb_df = df.ta.bbands(append=True) adiciona várias colunas: 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', etc.\n",
    "df.ta.bbands(append=True)\n",
    "\n",
    "# Índice de Força Relativa (RSI) de 14 períodos\n",
    "df.ta.rsi(length=14, append=True)\n",
    "\n",
    "print(\"Indicadores adicionados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a017da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tratando valores NaN...\n",
      "Número de linhas antes do tratamento de NaN: 500\n",
      "Número de linhas após o tratamento de NaN: 481\n",
      "Total de linhas removidas: 19\n"
     ]
    }
   ],
   "source": [
    "# --- 9 Tratamento de Valores NaN ---\n",
    "print(\"\\nTratando valores NaN...\")\n",
    "\n",
    "# Guarda o número de linhas antes de remover os NaNs\n",
    "initial_rows = len(df)\n",
    "\n",
    "# Remove todas as linhas que contêm qualquer valor NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Guarda o número de linhas depois de remover os NaNs\n",
    "final_rows = len(df)\n",
    "\n",
    "print(f\"Número de linhas antes do tratamento de NaN: {initial_rows}\")\n",
    "print(f\"Número de linhas após o tratamento de NaN: {final_rows}\")\n",
    "print(f\"Total de linhas removidas: {initial_rows - final_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c2d6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando o escalonamento dos dados (StandardScaler)...\n",
      "Escalonamento concluído!\n"
     ]
    }
   ],
   "source": [
    "### **10. Normalização/Escalonamento de Dados (StandardScaler)**\n",
    "print(\"\\nRealizando o escalonamento dos dados (StandardScaler)...\")\n",
    "# Certifique-se de que todas as colunas sejam numéricas antes de escalonar\n",
    "features_to_scale = df.columns.tolist()\n",
    "# Cria uma instância do StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# O resultado é um array NumPy, então o convertemos de volta para um DataFrame.\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[features_to_scale]),\n",
    "                         columns=features_to_scale,\n",
    "                         index=df.index)\n",
    "\n",
    "print(\"Escalonamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1ca4c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando os labels de Comprar/Vender/Manter...\n",
      "Labels criados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Criação dos Labels (Comprar/Vender/Manter) ---\n",
    "print(\"\\nCriando os labels de Comprar/Vender/Manter...\")\n",
    "\n",
    "look_forward_period = 5\n",
    "price_change_threshold = 0.005\n",
    "\n",
    "df['future_close'] = df['Close'].shift(-look_forward_period)\n",
    "df['price_change'] = (df['future_close'] - df['Close']) / df['Close']\n",
    "\n",
    "def get_label(change, threshold):\n",
    "    if change > threshold:\n",
    "        return 1  # Comprar\n",
    "    elif change < -threshold:\n",
    "        return -1 # Vender\n",
    "    else:\n",
    "        return 0  # Manter\n",
    "\n",
    "df['label'] = df['price_change'].apply(lambda x: get_label(x, price_change_threshold))\n",
    "\n",
    "df.drop(columns=['future_close', 'price_change'], inplace=True)\n",
    "df.dropna(inplace=True) # Remove as últimas linhas que não têm um 'future_close'\n",
    "\n",
    "print(\"Labels criados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "388d7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Dividir em Features (X) e Labels (y) e aplicar escalonamento\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Agora, escalonar as features (X)\n",
    "features_to_scale_final = X.columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[features_to_scale_final]),\n",
    "                        columns=features_to_scale_final,\n",
    "                        index=X.index)\n",
    "\n",
    "# Verificação final de NaNs após todo o pré-processamento\n",
    "if X_scaled.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\n",
    "    print(\"AVISO: Ainda existem NaNs em X_scaled ou y após o pré-processamento. Verifique!\")\n",
    "    print(X_scaled.isnull().sum())\n",
    "    print(y.isnull().sum())\n",
    "    exit() # Interrompe o processo se houver NaNs restantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f4bf8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeiras 5 linhas das Features ESCALONADAS (X):\n",
      "                         Open      High       Low     Close    Volume\n",
      "timestamp                                                            \n",
      "2025-07-04 21:00:00 -1.808420 -1.794964 -1.776291 -1.767656 -0.658310\n",
      "2025-07-04 22:00:00 -1.758144 -1.718464 -1.730263 -1.688546 -0.482024\n",
      "2025-07-04 23:00:00 -1.679291 -1.723990 -1.713631 -1.750847 -0.757669\n",
      "2025-07-05 00:00:00 -1.741385 -1.730884 -1.714316 -1.702111 -0.766956\n",
      "2025-07-05 01:00:00 -1.692813 -1.737359 -1.728447 -1.751562 -0.817997\n",
      "\n",
      "Últimas 5 linhas das Features ESCALONADAS (X):\n",
      "                         Open      High       Low     Close    Volume\n",
      "timestamp                                                            \n",
      "2025-07-25 12:00:00  0.221976  0.181368  0.157573  0.118263  0.876262\n",
      "2025-07-25 13:00:00  0.121591  0.168445  0.064265  0.143649  1.640418\n",
      "2025-07-25 14:00:00  0.146894  0.097435 -0.089234 -0.145463  1.972078\n",
      "2025-07-25 15:00:00 -0.141269 -0.002454 -0.087252  0.031068  0.814670\n",
      "2025-07-25 16:00:00  0.034681 -0.000468  0.086359  0.047104 -0.881851\n",
      "\n",
      "Primeiras 5 linhas dos Labels (y):\n",
      "timestamp\n",
      "2025-07-04 21:00:00    0\n",
      "2025-07-04 22:00:00    0\n",
      "2025-07-04 23:00:00    0\n",
      "2025-07-05 00:00:00    0\n",
      "2025-07-05 01:00:00    0\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Últimas 5 linhas dos Labels (y):\n",
      "timestamp\n",
      "2025-07-25 12:00:00    0\n",
      "2025-07-25 13:00:00    0\n",
      "2025-07-25 14:00:00    0\n",
      "2025-07-25 15:00:00    0\n",
      "2025-07-25 16:00:00    0\n",
      "Name: label, dtype: int64\n",
      "\n",
      "DataFrame de Features (X) criado com 500 linhas e 5 colunas.\n",
      "Series de Labels (y) criada com 500 elementos.\n"
     ]
    }
   ],
   "source": [
    "# 13. Exibir os primeiros e últimos dados das Features Escalonadas e Labels\n",
    "print(\"\\nPrimeiras 5 linhas das Features ESCALONADAS (X):\")\n",
    "print(X_scaled.head())\n",
    "\n",
    "print(\"\\nÚltimas 5 linhas das Features ESCALONADAS (X):\")\n",
    "print(X_scaled.tail())\n",
    "\n",
    "print(\"\\nPrimeiras 5 linhas dos Labels (y):\")\n",
    "print(y.head())\n",
    "\n",
    "print(\"\\nÚltimas 5 linhas dos Labels (y):\")\n",
    "print(y.tail())\n",
    "\n",
    "print(f\"\\nDataFrame de Features (X) criado com {len(X_scaled)} linhas e {len(X_scaled.columns)} colunas.\")\n",
    "print(f\"Series de Labels (y) criada com {len(y)} elementos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9219fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features escalonadas salvas com sucesso em 'BTCUSDT_1h_features_escalonadas.csv'\n",
      "Labels salvos com sucesso em 'BTCUSDT_1h_labels.csv'\n"
     ]
    }
   ],
   "source": [
    "# 14. Salvar os DataFrames processados (X_scaled e y)\n",
    "# É comum salvar as features e labels separadamente\n",
    "X_scaled_filename = f'{symbol}_{interval}_features_escalonadas.csv'\n",
    "y_filename = f'{symbol}_{interval}_labels.csv'\n",
    "\n",
    "X_scaled.to_csv(X_scaled_filename, index=True)\n",
    "y.to_csv(y_filename, index=True, header=True) # header=True para salvar o nome da coluna 'label'\n",
    "\n",
    "print(f\"\\nFeatures escalonadas salvas com sucesso em '{X_scaled_filename}'\")\n",
    "print(f\"Labels salvos com sucesso em '{y_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d523158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
