{"cells":[{"metadata":{"_cell_guid":"85e60258-69b7-75a0-6101-171d067448ed","_uuid":"3598b750c1667dd6b3f8cb57ad3e67ea27c8ff2e"},"cell_type":"markdown","source":"# How to get to TOP 25% with Simple Model using sklearn only"},{"metadata":{"_cell_guid":"782ec9c5-78c5-8330-5c07-235e9f40ad7f","_uuid":"2b8b1302050cba8e903f147ee2c08b5f6ee296ca"},"cell_type":"markdown","source":"## by Sergei Neviadomski"},{"metadata":{"_cell_guid":"1d6988bb-248e-dcaf-6cfb-d8295f2940a4","_uuid":"7e2a203a34218359ae5bff516a470ddd025100fb"},"cell_type":"markdown","source":"### Importing libraries and data"},{"metadata":{"_cell_guid":"23cd1b78-7b95-611d-9d4c-e71b49fb290a","_uuid":"56550cfb809efdf830c27e9659e548ae0f89384b"},"cell_type":"markdown","source":"That's my simple ensemble model that helped me to get to top 40%. I'll try to briefly show you all steps that I made during my analysis and model building."},{"metadata":{"_cell_guid":"8ae1f2f6-9488-9c61-45a4-5c72262d012b","_uuid":"b2a5e42ea07e63f20c211589656aaca5f81cd669","collapsed":true,"trusted":true},"cell_type":"code","source":"# Adding needed libraries and reading data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import ensemble, tree, linear_model\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.utils import shuffle\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52f7e2b6-5a6e-8bfa-dff4-85deb7534b16","_uuid":"1a9192c800daaa0b5632253a8449e1c94c5bbe88","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aeb12b52-935b-43d1-1a64-6edafe632fe7","_uuid":"49f6aecc49ec213c722fd15f61394d715686d6dd"},"cell_type":"markdown","source":"### Checking for NAs"},{"metadata":{"_cell_guid":"68505215-baa0-1ae4-3d38-b9d1e88e712c","_uuid":"e4e6f9d50cc141482be0c87f438befd1ca4aa640","trusted":true},"cell_type":"code","source":"#Checking for missing data\nNAs = pd.concat([train.isnull().sum(), test.isnull().sum()], axis=1, keys=['Train', 'Test'])\nNAs[NAs.sum(axis=1) > 0]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"661ab7ce-776e-c94c-514c-873166ed28e4","_uuid":"2080bdb0bb4d8973593137924c569e07b0ca4c19"},"cell_type":"markdown","source":"### Importing my functions"},{"metadata":{"_cell_guid":"a321c35d-73cc-e208-2119-527347b8a39f","_uuid":"cf23ca448677be73c301070be54861232f43bd16","collapsed":true,"trusted":true},"cell_type":"code","source":"# Prints R2 and RMSE scores\ndef get_score(prediction, lables):    \n    print('R2: {}'.format(r2_score(prediction, lables)))\n    print('RMSE: {}'.format(np.sqrt(mean_squared_error(prediction, lables))))\n\n# Shows scores for train and validation sets    \ndef train_test(estimator, x_trn, x_tst, y_trn, y_tst):\n    prediction_train = estimator.predict(x_trn)\n    # Printing estimator\n    print(estimator)\n    # Printing train scores\n    get_score(prediction_train, y_trn)\n    prediction_test = estimator.predict(x_tst)\n    # Printing test scores\n    print(\"Test\")\n    get_score(prediction_test, y_tst)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"58a295ad-4773-de3a-5417-bac520f0778f","_uuid":"99f3a531d02967e0f338030f29a0dab293a0c2fd"},"cell_type":"markdown","source":"### Splitting to features and labels and deleting variables I don't need"},{"metadata":{"_cell_guid":"519c524f-ed5d-1789-870a-730aa6113204","_uuid":"2cb8614cce04a75250a574c543d6876292813253","collapsed":true,"trusted":true},"cell_type":"code","source":"# Spliting to features and lables and deleting variable I don't need\ntrain_labels = train.pop('SalePrice')\n\nfeatures = pd.concat([train, test], keys=['train', 'test'])\n\n# I decided to get rid of features that have more than half of missing information or do not correlate to SalePrice\nfeatures.drop(['Utilities', 'RoofMatl', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'Heating', 'LowQualFinSF',\n               'BsmtFullBath', 'BsmtHalfBath', 'Functional', 'GarageYrBlt', 'GarageArea', 'GarageCond', 'WoodDeckSF',\n               'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal'],\n              axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cbc08e10-0318-4995-22b3-a0cfafc887c7","_uuid":"3efdf26728b1da256229011781836a475e6da614"},"cell_type":"markdown","source":"### Filling NAs and converting features"},{"metadata":{"_cell_guid":"17b717d9-0905-4f12-3eea-a2655110c1a5","_uuid":"a6c08abefe89aba51b78dddd71a41c0458d85915","collapsed":true,"trusted":true},"cell_type":"code","source":"# MSSubClass as str\nfeatures['MSSubClass'] = features['MSSubClass'].astype(str)\n\n# MSZoning NA in pred. filling with most popular values\nfeatures['MSZoning'] = features['MSZoning'].fillna(features['MSZoning'].mode()[0])\n\n# LotFrontage  NA in all. I suppose NA means 0\nfeatures['LotFrontage'] = features['LotFrontage'].fillna(features['LotFrontage'].mean())\n\n# Alley  NA in all. NA means no access\nfeatures['Alley'] = features['Alley'].fillna('NOACCESS')\n\n# Converting OverallCond to str\nfeatures.OverallCond = features.OverallCond.astype(str)\n\n# MasVnrType NA in all. filling with most popular values\nfeatures['MasVnrType'] = features['MasVnrType'].fillna(features['MasVnrType'].mode()[0])\n\n# BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2\n# NA in all. NA means No basement\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    features[col] = features[col].fillna('NoBSMT')\n\n# TotalBsmtSF  NA in pred. I suppose NA means 0\nfeatures['TotalBsmtSF'] = features['TotalBsmtSF'].fillna(0)\n\n# Electrical NA in pred. filling with most popular values\nfeatures['Electrical'] = features['Electrical'].fillna(features['Electrical'].mode()[0])\n\n# KitchenAbvGr to categorical\nfeatures['KitchenAbvGr'] = features['KitchenAbvGr'].astype(str)\n\n# KitchenQual NA in pred. filling with most popular values\nfeatures['KitchenQual'] = features['KitchenQual'].fillna(features['KitchenQual'].mode()[0])\n\n# FireplaceQu  NA in all. NA means No Fireplace\nfeatures['FireplaceQu'] = features['FireplaceQu'].fillna('NoFP')\n\n# GarageType, GarageFinish, GarageQual  NA in all. NA means No Garage\nfor col in ('GarageType', 'GarageFinish', 'GarageQual'):\n    features[col] = features[col].fillna('NoGRG')\n\n# GarageCars  NA in pred. I suppose NA means 0\nfeatures['GarageCars'] = features['GarageCars'].fillna(0.0)\n\n# SaleType NA in pred. filling with most popular values\nfeatures['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])\n\n# Year and Month to categorical\nfeatures['YrSold'] = features['YrSold'].astype(str)\nfeatures['MoSold'] = features['MoSold'].astype(str)\n\n# Adding total sqfootage feature and removing Basement, 1st and 2nd floor features\nfeatures['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\nfeatures.drop(['TotalBsmtSF', '1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"feb8c5fb-3360-aa1d-73a0-914bc8522cb1","_uuid":"306d50621a1cdf3358377d6df07ead7eea486625"},"cell_type":"markdown","source":"### Log transformation"},{"metadata":{"_cell_guid":"12b9abde-c4af-a278-5e8a-96db1d976a77","_uuid":"a55444a0d0c03a06808f3ed80153f929365d5a6e","trusted":true},"cell_type":"code","source":"# Our SalesPrice is skewed right (check plot below). I'm logtransforming it. \nax = sns.distplot(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"441e1db5-49f1-f182-8870-b4b207796160","_uuid":"a06242561cf82df0b9ff5294b08be096a5b035e8","collapsed":true,"trusted":true},"cell_type":"code","source":"## Log transformation of labels\ntrain_labels = np.log(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"023c4ab0-6791-fd0f-e4aa-a0bd885b0425","_uuid":"4499617796a0776fd5ad9366898764c6a6bfbd5f","trusted":true},"cell_type":"code","source":"## Now it looks much better\nax = sns.distplot(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f82fdd70-55e4-27b2-cdae-3a3657ff6e74","_uuid":"73634d3676d15f388f5717c68dd2aade76460085"},"cell_type":"markdown","source":"### Standardizing numeric data"},{"metadata":{"_cell_guid":"7625eaed-2624-0c12-503a-4a3be950bccd","_uuid":"0e584588e5bced98ba77f5c22b2f824482fd579a","collapsed":true,"trusted":true},"cell_type":"code","source":"## Standardizing numeric features\nnumeric_features = features.loc[:,['LotFrontage', 'LotArea', 'GrLivArea', 'TotalSF']]\nnumeric_features_standardized = (numeric_features - numeric_features.mean())/numeric_features.std()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8746570b-7f23-e4ea-995c-d50fb0a9105f","_uuid":"7835b613c66b0aac9f9b344b07811a4b4f34d95a","trusted":true},"cell_type":"code","source":"ax = sns.pairplot(numeric_features_standardized)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fd73643f-4fae-7242-84eb-9a1c9f81b90f","_uuid":"0704b29a86a43445baf03feaae64b1b4d37f6d4c"},"cell_type":"markdown","source":"### Converting categorical data to dummies"},{"metadata":{"_cell_guid":"be16f346-dfab-7abc-e4f9-0a58bbccbd1d","_uuid":"68951a027eac8bc65a77e613b5d13b1ec4db677c","collapsed":true,"trusted":true},"cell_type":"code","source":"# Getting Dummies from Condition1 and Condition2\nconditions = set([x for x in features['Condition1']] + [x for x in features['Condition2']])\ndummies = pd.DataFrame(data=np.zeros((len(features.index), len(conditions))),\n                       index=features.index, columns=conditions)\nfor i, cond in enumerate(zip(features['Condition1'], features['Condition2'])):\n    dummies.ix[i, cond] = 1\nfeatures = pd.concat([features, dummies.add_prefix('Condition_')], axis=1)\nfeatures.drop(['Condition1', 'Condition2'], axis=1, inplace=True)\n\n# Getting Dummies from Exterior1st and Exterior2nd\nexteriors = set([x for x in features['Exterior1st']] + [x for x in features['Exterior2nd']])\ndummies = pd.DataFrame(data=np.zeros((len(features.index), len(exteriors))),\n                       index=features.index, columns=exteriors)\nfor i, ext in enumerate(zip(features['Exterior1st'], features['Exterior2nd'])):\n    dummies.ix[i, ext] = 1\nfeatures = pd.concat([features, dummies.add_prefix('Exterior_')], axis=1)\nfeatures.drop(['Exterior1st', 'Exterior2nd', 'Exterior_nan'], axis=1, inplace=True)\n\n# Getting Dummies from all other categorical vars\nfor col in features.dtypes[features.dtypes == 'object'].index:\n    for_dummy = features.pop(col)\n    features = pd.concat([features, pd.get_dummies(for_dummy, prefix=col)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"62a1ba69-dd48-e20f-e593-d99f45fba734","_uuid":"71d58ef755ba6f9c602f176a0c90bea351054a0d"},"cell_type":"markdown","source":"### Obtaining standardized dataset"},{"metadata":{"_cell_guid":"916c9c3c-4ca7-8759-3d51-9c494640b287","_uuid":"1df73806fd5aba6b9cc9625ccd82025aadb67490","collapsed":true,"trusted":true},"cell_type":"code","source":"### Copying features\nfeatures_standardized = features.copy()\n\n### Replacing numeric features by standardized values\nfeatures_standardized.update(numeric_features_standardized)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dcbf12f4-a6ba-02be-f727-fc19ea6f90b4","_uuid":"4294a716d1489b98544199cd2952741ff7b3e54a"},"cell_type":"markdown","source":"### Splitting train and test features"},{"metadata":{"_cell_guid":"cf160a98-9ecc-48ae-7bba-b6adcb676bc2","_uuid":"22406d3ab0dc8e72309764ad9bbde5bddcd61252","collapsed":true,"trusted":true},"cell_type":"code","source":"### Splitting features\ntrain_features = features.loc['train'].drop('Id', axis=1).select_dtypes(include=[np.number]).values\ntest_features = features.loc['test'].drop('Id', axis=1).select_dtypes(include=[np.number]).values\n\n### Splitting standardized features\ntrain_features_st = features_standardized.loc['train'].drop('Id', axis=1).select_dtypes(include=[np.number]).values\ntest_features_st = features_standardized.loc['test'].drop('Id', axis=1).select_dtypes(include=[np.number]).values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3cb77904-3446-f472-4ea8-a59e499e8c82","_uuid":"9025ed78a8040c7bac8a586b610ad08d1167f2e9"},"cell_type":"markdown","source":"### Splitting to train and validation sets"},{"metadata":{"_cell_guid":"40f40adb-2195-3705-e0d8-dae02945e6aa","_uuid":"d90327002dcbbc8e448cbef3c841a0189927a213","collapsed":true,"trusted":true},"cell_type":"code","source":"### Shuffling train sets\ntrain_features_st, train_features, train_labels = shuffle(train_features_st, train_features, train_labels, random_state = 5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9381503b-8c56-dc28-9c12-ebabe6bff903","_uuid":"9a2a3ac414e2f99b5312bfe4936ee7a5b483cad4","collapsed":true,"trusted":true},"cell_type":"code","source":"### Splitting\nx_train, x_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.1, random_state=200)\nx_train_st, x_test_st, y_train_st, y_test_st = train_test_split(train_features_st, train_labels, test_size=0.1, random_state=200)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"711173eb-c271-676d-5ab2-dd5d70cef0f0","_uuid":"38bd3b1715c7594d5a43b087c630eda4a74587b7"},"cell_type":"markdown","source":"## First level models"},{"metadata":{"_cell_guid":"52a5384b-ea50-08de-7057-111a0c041bce","_uuid":"f9174d11d0a07b7e3f0adc30d4120d557cbe65b5"},"cell_type":"markdown","source":"My analysis revealed that Gradient Boosting and Elastic Net (using Standardized Features) show best results."},{"metadata":{"_cell_guid":"651f1613-5f21-95f6-8b0a-a5e3b588ddd2","_uuid":"198d2fdf168091b79288ed8c81625a24b4b3a3c5"},"cell_type":"markdown","source":"### Elastic Net"},{"metadata":{"_cell_guid":"66f1b8e0-def2-697e-c86c-2b96f337d209","_uuid":"c8df69c3b69eb3131be3d936bbe385f57dc37204"},"cell_type":"markdown","source":"I'm using ElasticNetCV estimator to choose best alpha and l1_ratio for my Elastic Net model."},{"metadata":{"_cell_guid":"faa54d71-cef2-0c49-43bb-3e9b5ec66966","_uuid":"e5be8ad45ab3d3bca3865c527140b0eea62d1af6","trusted":true},"cell_type":"code","source":"ENSTest = linear_model.ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], l1_ratio=[.01, .1, .5, .9, .99], max_iter=5000).fit(x_train_st, y_train_st)\ntrain_test(ENSTest, x_train_st, x_test_st, y_train_st, y_test_st)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8d4cd7b-4a07-4b1b-b188-ac0636bcf62a","_uuid":"25b2995414156185d0438f9d43bff0f514422ae1","trusted":true},"cell_type":"code","source":"# Average R2 score and standart deviation of 5-fold cross-validation\nscores = cross_val_score(ENSTest, train_features_st, train_labels, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e356e62-4597-6801-50d1-7c6441131755","_uuid":"1435e9c157bf2ee7960c0104d09c4ee64680be4e"},"cell_type":"markdown","source":"### Gradient Boosting"},{"metadata":{"_cell_guid":"cf76ad42-de6e-3a67-1ab0-c59e873013ed","_uuid":"54b91e9002e111722da6fab2c079148abf58764b"},"cell_type":"markdown","source":"We use a lot of features and have many outliers. So I'm using max_features='sqrt' to reduce overfitting of my model. I also use loss='huber' because it more tolerant to outliers. All other hyper-parameters was chosen using GridSearchCV."},{"metadata":{"_cell_guid":"95f4f003-c292-77aa-ade9-5cda8a5bb3b2","_uuid":"f35b0461f44dff648a8a12bee0229f4a42c65751","trusted":true},"cell_type":"code","source":"GBest = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features='sqrt',\n                                               min_samples_leaf=15, min_samples_split=10, loss='huber').fit(x_train, y_train)\ntrain_test(GBest, x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"63ea7b81-1190-5354-c101-bb3f3cf494e1","_uuid":"89f930a784e92c71d3ceeb657a03b9c192fdc677","trusted":true},"cell_type":"code","source":"# Average R2 score and standart deviation of 5-fold cross-validation\nscores = cross_val_score(GBest, train_features_st, train_labels, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b7cad65b-cfd7-2fc5-2458-a8f35fe44647","_uuid":"b04448915e24859872a2353b0ffc914550e98fc5"},"cell_type":"markdown","source":"## Ensembling final model"},{"metadata":{"_cell_guid":"044e8e90-ec67-f6cc-0a73-a3c9635fca0d","_uuid":"a9aea959c2d58fae0734d8c02ba454c63a56e23c"},"cell_type":"markdown","source":"My final ensemble model is an average of Gradient Boosting and Elastic Net predictions. But before that I retrained my models on all train data."},{"metadata":{"_cell_guid":"bf7a74b6-8487-8507-40d7-253bd0af0561","_uuid":"a5e015b973a02d894cd352f2e25415e15b534691","collapsed":true,"trusted":true},"cell_type":"code","source":"# Retraining models\nGB_model = GBest.fit(train_features, train_labels)\nENST_model = ENSTest.fit(train_features_st, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"31e1c6e0-10e2-6695-7b07-0ac8f025800a","_uuid":"151ded0a3a7fa99eaa1901e995b5f77175f860fa","collapsed":true,"trusted":true},"cell_type":"code","source":"## Getting our SalePrice estimation\nFinal_labels = (np.exp(GB_model.predict(test_features)) + np.exp(ENST_model.predict(test_features_st))) / 2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"703ea3cf-f3a1-d5e9-472a-42e760790ae0","_uuid":"c25eb7ab90f21c93dc4d3bf61dd08bdab10dd883","collapsed":true,"trusted":true},"cell_type":"code","source":"## Saving to CSV\npd.DataFrame({'Id': test.Id, 'SalePrice': Final_labels}).to_csv('2017-02-28.csv', index =False)    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f07ce760-2707-7150-536d-b07f0247ed96","_uuid":"3b2685e2981daae3e924d5d6b401c9071e7a6736"},"cell_type":"markdown","source":"### I'll be glad to hear suggestions on improving my models.\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}