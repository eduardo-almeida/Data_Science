{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O k-Nearest Neighbors (ou KNN) é uma técnica de classificação bem simples que consiste em prever uma classe alvo ao encontrar a(s) classe(s) vizinha(s) mais próxima(s). \n",
    "\n",
    "\n",
    "Neste tutorial iremos apresentar a implementação do algoritmo k-Nearest Neighbors. Usaremos como exemplo o conjunto de dados Abalone, que são um tipo de moluscos gastrópodes. Veja neste [link](https://archive.ics.uci.edu/ml/datasets/abalone).\n",
    "\n",
    "Este problema deseja predizer a idade de um abalone através de medidas físicas. A idade de um abalone é determinada cortando a concha através do cone, manchando-a e contando o número de anéis através de um microscópio - uma tarefa chata e demorada. Outra medidas que são mais facéis de obter, são usadas para prever a idade, como padrões climáticos e localização (portanto, disponibilidade de alimentos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passos do Tutorial\n",
    "\n",
    "1. Tratar os dados: carregar os dados do arquivo CSV e tratar o conjunto de dados.\n",
    "2. Calcular distância euclidiana\n",
    "3. Obter vizinhos: pegar os $k$ vizinhos mais próximos\n",
    "4. Fazer predições\n",
    "5. Avaliar a precisão: avaliar a precisão das previsões feitas para um conjunto de dados de teste como a porcentagem correta de todas as previsões feitas.\n",
    "\n",
    "\n",
    "## 1. Tratar Dados\n",
    "\n",
    "**1.1 Carregar arquivo**\n",
    "\n",
    "A primeira coisa que precisamos fazer é carregar nosso arquivo de dados. Os dados estão no formato CSV sem linha de cabeçalho. Podemos abrir o arquivo com a função open e ler as linhas de dados usando a função de leitor no módulo csv.\n",
    "\n",
    "Também precisamos converter os atributos que foram carregados como strings em números para que possamos trabalhar com eles. Abaixo está a função *load_csv( )* para carregar o conjunto de dados Abalone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de dados abalone.csv carregado com 4177 linhas e 9 colunas\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# carregar um arquivo csv\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Carregando dataset Abalone\n",
    "filename = 'abalone.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "print ('Arquivo de dados {0} carregado com {1} linhas e {2} colunas'.format(filename, len(dataset), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Converter Valores Não-numéricos**\n",
    "\n",
    "É importante que todos os valores sejam numéricos para que possamos caclular as distâncias euclidianas\n",
    "\n",
    "Abaixo funções que convertem *string* para *float* ou *string* para *int*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converte string para float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Converte string para int\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Normalizar**\n",
    "\n",
    "Algumas colunas têm variância maior que outras, por isso é importante normalizar todas as colunas. Para isso calcularemos primeiro os mínimos e máximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Calcular Distância Euclidiana\n",
    "\n",
    "O primeiro passo necessário é calcular a distância entre duas linhas em um conjunto de dados. Linhas de dados\n",
    "são constituídos principalmente por números e uma maneira fácil de calcular a distância entre duas linhas ou\n",
    "vetores de números é desenhar uma linha reta. Isso faz sentido em 2D ou 3D e escala muito bem\n",
    "para maiores dimensões. Podemos calcular a distância da linha reta entre dois vetores usando\n",
    "a medida de distância euclidiana. É calculado como a raiz quadrada da soma do quadrado\n",
    "diferenças entre os dois vetores. Com a distância euclidiana, quanto menos o valor, maior a similaridade. O valor $0$ significa que não há nenhuma diferença entre dois registros.\n",
    "\n",
    "Abaixo temos a função que calcula isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.3290173915275787\n",
      "1.9494646655653247\n",
      "1.5591439385540549\n",
      "0.5356280721938492\n",
      "4.850940186986411\n",
      "2.592833759950511\n",
      "4.214227042632867\n",
      "6.522409988228337\n",
      "4.985585382449795\n"
     ]
    }
   ],
   "source": [
    "# Teste da função euclidean_distance\n",
    "\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "           [1.465489372,2.362125076,0],\n",
    "           [3.396561688,4.400293529,0],\n",
    "           [1.38807019,1.850220317,0],\n",
    "           [3.06407232,3.005305973,0],\n",
    "           [7.627531214,2.759262235,1],\n",
    "           [5.332441248,2.088626775,1],\n",
    "           [6.922596716,1.77106367,1],\n",
    "           [8.675418651,-0.242068655,1],\n",
    "           [7.673756466,3.508563011,1]]\n",
    "\n",
    "row0 = dataset[0]\n",
    "\n",
    "for row in dataset:\n",
    "    distance = euclidean_distance(row0, row)\n",
    "    print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Obter Vizinhos\n",
    "\n",
    "Os vizinhos para um novo dado no conjunto de dados são as k instâncias mais próximas. Para localizar os vizinhos para um novo dado dentro de um conjunto de dados, devemos primeiro calcular a distância entre cada registro no conjunto de dados para o novo dado. Nós podemos fazer isso usando nossa função de distância acima. Uma vez que as distâncias são calculadas, devemos ordenar todas os registros no conjunto de dados de treinamento por sua distância entre o novo dado. Podemos então selecionar o top k para retornar como os vizinhos mais parecidos.\n",
    "\n",
    "\n",
    "Podemos fazer isso guardando a distância de cada registro no conjunto de dados como uma tupla, ordenar a lista de tuplas pela distância(em ordem decrescente) e depois recuperar os vizinhos.\n",
    "\n",
    "Abaixo está uma função chamada *get_neighbors( )* que implementa isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7810836, 2.550537003, 0]\n",
      "[1.465489372, 2.362125076, 0]\n",
      "[3.396561688, 4.400293529, 0]\n"
     ]
    }
   ],
   "source": [
    "# Teste da função get_neighbors\n",
    "\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "           [1.465489372,2.362125076,0],\n",
    "           [3.396561688,4.400293529,0],\n",
    "           [1.38807019,1.850220317,0],\n",
    "           [3.06407232,3.005305973,0],\n",
    "           [7.627531214,2.759262235,1],\n",
    "           [5.332441248,2.088626775,1],\n",
    "           [6.922596716,1.77106367,1],\n",
    "           [8.675418651,-0.242068655,1],\n",
    "           [7.673756466,3.508563011,1]]\n",
    "\n",
    "neighbors = get_neighbors(dataset, dataset[0], 3)\n",
    "for neighbor in neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fazer Predições\n",
    "\n",
    "\n",
    "Os vizinhos mais semelhantes coletados do conjunto de dados de treinamento podem ser usados para fazer previsões.\n",
    "No caso da classificação, podemos retornar a classe mais representada entre os vizinhos. Podemos conseguir isso executando a função *max( )* na lista de valores de saída dos vizinhos. Dada uma lista de valores de classe observadas nos vizinhos, a função *max( )* toma um conjunto de valores de classe únicos e chama a contagem na lista de valores de classe para cada valor de classe no conjunto.\n",
    "\n",
    "Abaixo está a função denominada *predict_classification( )* que implementa isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Expected 0, Got 0. \n"
     ]
    }
   ],
   "source": [
    "# Teste da função predict_classification\n",
    "\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "           [1.465489372,2.362125076,0],\n",
    "           [3.396561688,4.400293529,0],\n",
    "           [1.38807019,1.850220317,0],\n",
    "           [3.06407232,3.005305973,0],\n",
    "           [7.627531214,2.759262235,1],\n",
    "           [5.332441248,2.088626775,1],\n",
    "           [6.922596716,1.77106367,1],\n",
    "           [8.675418651,-0.242068655,1],\n",
    "           [7.673756466,3.508563011,1]]\n",
    "\n",
    "prediction = predict_classification(dataset, dataset[0], 3)\n",
    "print( ' Expected %d, Got %d. ' % (dataset[0][-1], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avaliar Precisão\n",
    "\n",
    "**5.1 Calcular Acurácea**\n",
    "\n",
    "As previsões podem ser comparadas com os valores de classe no conjunto de dados de teste. A acurácia da classificação pode ser calculada como uma relação de precisão entre 0 e 100%. A função *accuracy_metric( )* calculará essa relação de precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Avaliar Algoritmo**\n",
    "\n",
    "Abaixo temos a função que avalia o algoritmo usando uma divisão de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "        row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de Estudo Abalone\n",
    "\n",
    "Aplicaremos o algoritmo k-Nearest Neighbors ao conjunto de dados do Abalone. O primeiro passo é carregar o conjunto de dados e converter os dados carregados para números com os quais podemos usar o cálculo da distância euclidiana. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [25.269461077844312, 21.077844311377245, 24.07185628742515, 21.79640718562874, 24.550898203592812]\n",
      "Mean Accuracy: 23.353%\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# Carregar um arquivo CSV\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Converter string para float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Converter string para integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Achar os maximos e minimos de cada coluna\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "# Normalizar o conjunto de dados\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Dividir o conjunto de dados em k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calcular porcentagem de precisao\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Avaliar o algoritmo usando a validação cruzada\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Calcular a distância euclidiana entre dois vetores\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "# Achar os vizinhos mais proximos\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "# Fazer a predição com os vizinhos\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    "\n",
    "# Algoritmo kNN\n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_classification(train, row, num_neighbors)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# Teste\n",
    "seed(1)\n",
    "# Carregar e preparar o conjunto de dados\n",
    "filename = 'abalone.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(1, len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "# Converter primeira conluna para integer\n",
    "str_column_to_int(dataset, 0)\n",
    "# Avaliar o algoritmo\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um valor de $k = 5$ vizinhos foi usado para fazer previsões. Você pode experimentar com $k$ maiores para aumentar a precisão. Podemos ver que a precisão média de 23% é melhor do que a\n",
    "linha de base de 16%, mas é bastante pobre em geral. Isto é devido ao grande número de classes\n",
    "tornando a precisão um \"pobre juiz\" de habilidade sobre esse problema. Esse fato, combinado com o fato de que\n",
    "Muitas das classes têm poucos ou um exemplo também tornam o problema desafiador.\n",
    "\n",
    "\n",
    "Nós também podemos modelar o conjunto de dados como um problema de modelagem preditiva de regressão. Isto é porque\n",
    "os valores da classe têm uma relação ordinal natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de Estudo Abalone como Regressão\n",
    "\n",
    "A regressão pode ser uma maneira mais útil de modelar este problema, dado o grande número de classes\n",
    "e dispersão de alguns valores de classe. Podemos facilmente mudar nosso exemplo acima para regressão por\n",
    "alterando KNN para prever a média dos vizinhos e usando Root Mean Squared Error(erro quadrado médio) para\n",
    "avaliar previsões. Abaixo está um exemplo completo com essas mudanças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [2.170383116929243, 2.2087035241256405, 2.2321118594939215, 2.4013070293283603, 2.2274928845898017]\n",
      "Mean RMSE: 2.248\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors on the Abalone Dataset for Regression\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# Carregar um arquivo CSV\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Converter string para float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Converter string para integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Achar os maximos e minimos de cada coluna\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "# Normalizar o conjunto de dados\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Dividr o conjunto de dados em k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calcular erro medio\n",
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return sqrt(mean_error)\n",
    "\n",
    "# Avaliar o algoritmo usando a validacao cruzada\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        rmse = rmse_metric(actual, predicted)\n",
    "        scores.append(rmse)\n",
    "    return scores\n",
    "\n",
    "# Calcular a distância euclidiana entre dois vetores\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "# Achar os vizinhos mais proximos\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "# Fazer a predição com os vizinhos\n",
    "def predict_regression(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = sum(output_values) / float(len(output_values))\n",
    "    return prediction\n",
    "\n",
    "# Algoritmo kNN\n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_regression(train, row, num_neighbors)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# Teste\n",
    "seed(1)\n",
    "# Carregar e preparar o conjunto de dados\n",
    "filename = 'abalone.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(1, len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "# converter primeira conluna para integer\n",
    "str_column_to_int(dataset, 0)\n",
    "# avaliar o algoritmo\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao executar este exemplo, imprime o RMSE em cada fold e o RMSE médio em todas os folds. Podemos ver que o RMSE de 2.242 anéis é melhor do que a linha de base de 3.222 anéis. Nós também temos um modelo que talvez seja mais útil no domínioe e com um desempenho mais fácil de compreender."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
