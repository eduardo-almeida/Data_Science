{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e05c06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-binance\n",
    "# !pip install python-dotenv\n",
    "# !pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "942fb33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e72fd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Para dividir os dados\n",
    "from sklearn.ensemble import RandomForestClassifier # O algoritmo de Floresta Aleatória\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # Métricas de avaliação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c3755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "API_SECRET = os.getenv(\"API_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b30407d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com a Binance estabelecida com sucesso!\n",
      "\n",
      "Buscando os últimos 2500 candlesticks de BTCUSDT no intervalo de 1h...\n"
     ]
    }
   ],
   "source": [
    "if not API_KEY or not API_SECRET:\n",
    "    print(\"Erro: As chaves API_KEY ou API_SECRET não foram carregadas do arquivo .env.\")\n",
    "    print(\"Verifique se o arquivo .env existe na mesma pasta e se as variáveis estão corretas.\")\n",
    "    exit() # Sai do programa se as chaves não forem encontradas\n",
    "\n",
    "# 4. Inicializa o cliente da Binance (mesmo código de antes)\n",
    "try:\n",
    "    client = Client(API_KEY, API_SECRET)\n",
    "    print(\"Conexão com a Binance estabelecida com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao conectar com a Binance: {e}\")\n",
    "    print(\"Verifique suas chaves de API e sua conexão com a internet.\")\n",
    "    exit()\n",
    "\n",
    "# 5. Define os parâmetros para a busca dos dados de candlestick (mesmo código de antes)\n",
    "symbol = 'BTCUSDT'\n",
    "interval = '1h'\n",
    "limit = 2500\n",
    "\n",
    "print(f\"\\nBuscando os últimos {limit} candlesticks de {symbol} no intervalo de {interval}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9095dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Faz a requisição para a API da Binance\n",
    "klines = client.get_historical_klines(symbol, interval, limit=limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6deb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Processa os dados brutos e os organiza em um DataFrame do Pandas\n",
    "data = []\n",
    "for kline in klines:\n",
    "    data.append({\n",
    "        'timestamp': kline[0],\n",
    "        'open': float(kline[1]),\n",
    "        'high': float(kline[2]),\n",
    "        'low': float(kline[3]),\n",
    "        'close': float(kline[4]),\n",
    "        'volume': float(kline[5])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Armazenar o DataFrame original antes de renomear colunas\n",
    "# para que possamos usar 'close' para o cálculo do label\n",
    "df_original_cols = df.copy()\n",
    "\n",
    "# Assegura que as colunas numéricas estão no tipo correto para pandas_ta\n",
    "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354794b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adicionando indicadores técnicos ao DataFrame...\n",
      "Indicadores adicionados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- 8. Adicionar Indicadores Técnicos (Feature Engineering) ---\n",
    "print(\"\\nAdicionando indicadores técnicos ao DataFrame...\")\n",
    "\n",
    "# Média Móvel Simples (SMA) de 20 períodos\n",
    "# df.ta.sma(length=20, append=True) adiciona a coluna 'SMA_20' diretamente ao DataFrame\n",
    "df.ta.sma(length=20, append=True)\n",
    "\n",
    "# Bandas de Bollinger (BBands)\n",
    "# bb_df = df.ta.bbands(append=True) adiciona várias colunas: 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', etc.\n",
    "df.ta.bbands(append=True)\n",
    "\n",
    "# Índice de Força Relativa (RSI) de 14 períodos\n",
    "df.ta.rsi(length=14, append=True)\n",
    "\n",
    "print(\"Indicadores adicionados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "770dfda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tratando valores NaN...\n",
      "Número de linhas antes do tratamento de NaN: 500\n",
      "Número de linhas após o tratamento de NaN: 481\n",
      "Total de linhas removidas: 19\n"
     ]
    }
   ],
   "source": [
    "# --- 9 Tratamento de Valores NaN ---\n",
    "print(\"\\nTratando valores NaN...\")\n",
    "\n",
    "# Guarda o número de linhas antes de remover os NaNs\n",
    "initial_rows = len(df)\n",
    "\n",
    "# Remove todas as linhas que contêm qualquer valor NaN\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Guarda o número de linhas depois de remover os NaNs\n",
    "final_rows = len(df)\n",
    "\n",
    "print(f\"Número de linhas antes do tratamento de NaN: {initial_rows}\")\n",
    "print(f\"Número de linhas após o tratamento de NaN: {final_rows}\")\n",
    "print(f\"Total de linhas removidas: {initial_rows - final_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4be32e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando o escalonamento dos dados (StandardScaler)...\n",
      "Escalonamento concluído!\n"
     ]
    }
   ],
   "source": [
    "### **10. Normalização/Escalonamento de Dados (StandardScaler)**\n",
    "print(\"\\nRealizando o escalonamento dos dados (StandardScaler)...\")\n",
    "# Certifique-se de que todas as colunas sejam numéricas antes de escalonar\n",
    "features_to_scale = df.columns.tolist()\n",
    "# Cria uma instância do StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# O resultado é um array NumPy, então o convertemos de volta para um DataFrame.\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[features_to_scale]),\n",
    "                         columns=features_to_scale,\n",
    "                         index=df.index)\n",
    "\n",
    "print(\"Escalonamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c0e416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando os labels de Comprar/Vender/Manter...\n",
      "Labels criados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Criação dos Labels (Comprar/Vender/Manter) ---\n",
    "print(\"\\nCriando os labels de Comprar/Vender/Manter...\")\n",
    "\n",
    "look_forward_period = 5\n",
    "price_change_threshold = 0.005\n",
    "\n",
    "df['future_close'] = df['Close'].shift(-look_forward_period)\n",
    "df['price_change'] = (df['future_close'] - df['Close']) / df['Close']\n",
    "\n",
    "def get_label(change, threshold):\n",
    "    if change > threshold:\n",
    "        return 1  # Comprar\n",
    "    elif change < -threshold:\n",
    "        return -1 # Vender\n",
    "    else:\n",
    "        return 0  # Manter\n",
    "\n",
    "df['label'] = df['price_change'].apply(lambda x: get_label(x, price_change_threshold))\n",
    "\n",
    "df.drop(columns=['future_close', 'price_change'], inplace=True)\n",
    "df.dropna(inplace=True) # Remove as últimas linhas que não têm um 'future_close'\n",
    "\n",
    "print(\"Labels criados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81c24f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Dividir em Features (X) e Labels (y) e aplicar escalonamento\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Agora, escalonar as features (X)\n",
    "features_to_scale_final = X.columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[features_to_scale_final]),\n",
    "                        columns=features_to_scale_final,\n",
    "                        index=X.index)\n",
    "\n",
    "# Verificação final de NaNs após todo o pré-processamento\n",
    "if X_scaled.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\n",
    "    print(\"AVISO: Ainda existem NaNs em X_scaled ou y após o pré-processamento. Verifique!\")\n",
    "    print(X_scaled.isnull().sum())\n",
    "    print(y.isnull().sum())\n",
    "    exit() # Interrompe o processo se houver NaNs restantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92a72176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dividindo os dados em conjuntos de treino e teste...\n",
      "Tamanho do conjunto de treino (X_train): 400 linhas\n",
      "Tamanho do conjunto de teste (X_test): 100 linhas\n"
     ]
    }
   ],
   "source": [
    "# --- 12. Divisão dos Dados em Conjuntos de Treino e Teste ---\n",
    "print(\"\\nDividindo os dados em conjuntos de treino e teste...\")\n",
    "\n",
    "# test_size=0.20 significa que 20% dos dados serão para teste, 80% para treino.\n",
    "# random_state=42 garante que a divisão seja a mesma toda vez que você rodar o código,\n",
    "# o que é bom para reprodutibilidade.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=42, stratify=y)\n",
    "# stratify=y é importante para problemas de classificação desbalanceados,\n",
    "# garantindo que a proporção de cada classe (1, 0, -1) seja mantida tanto no treino quanto no teste.\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino (X_train): {len(X_train)} linhas\")\n",
    "print(f\"Tamanho do conjunto de teste (X_test): {len(X_test)} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6e9dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o treinamento do modelo RandomForestClassifier...\n",
      "Treinamento do modelo concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# --- 13. Treinamento do Modelo de Classificação (Random Forest) ---\n",
    "print(\"\\nIniciando o treinamento do modelo RandomForestClassifier...\")\n",
    "\n",
    "# Cria uma instância do modelo RandomForestClassifier\n",
    "# n_estimators: número de árvores na floresta (mais árvores geralmente melhor, mas mais lento)\n",
    "# random_state: para reprodutibilidade\n",
    "# class_weight: importante para classes desbalanceadas. 'balanced' tenta ajustar pesos inversamente proporcionais\n",
    "# à frequência das classes.\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Treinamento do modelo concluído com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5e144f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando a avaliação do modelo...\n",
      "\n",
      "Acurácia do modelo no conjunto de teste: 0.6400\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.38      0.46        16\n",
      "           0       0.70      0.82      0.75        65\n",
      "           1       0.36      0.26      0.30        19\n",
      "\n",
      "    accuracy                           0.64       100\n",
      "   macro avg       0.55      0.48      0.51       100\n",
      "weighted avg       0.62      0.64      0.62       100\n",
      "\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[ 6  9  1]\n",
      " [ 4 53  8]\n",
      " [ 0 14  5]]\n"
     ]
    }
   ],
   "source": [
    "# --- 14. Avaliação do Modelo ---\n",
    "print(\"\\nIniciando a avaliação do modelo...\")\n",
    "\n",
    "# Faz previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcula a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAcurácia do modelo no conjunto de teste: {accuracy:.4f}\")\n",
    "\n",
    "# Exibe o relatório de classificação (precisão, recall, f1-score para cada classe)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Exibe a matriz de confusão\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "# A matriz mostra:\n",
    "# Linhas: Valores Reais (True Labels)\n",
    "# Colunas: Valores Previstos (Predicted Labels)\n",
    "# Ex: Célula (0, 1) = Quantas vezes o modelo previu '1' (Comprar) quando o real era '0' (Manter)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096788c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
